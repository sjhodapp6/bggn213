---
title: "class09"
author: 'Stefanie Hodapp (PID: A53300084)'
date: "10/27/2021"
output:
  pdf_document: default
  html_document: default
always_allow_html: yes
---

```{r}
fna.data <- "WisconsinCancer.csv"
```

Read in data and store as wisc.df

```{r}
wisc.df <- read.csv(fna.data, row.names=1)
head(wisc.df)
```

Remove first column

```{r}
wisc.data <- wisc.df[,-1]
```

Create a diagnosis vector for later

```{r}
diagnosis <- wisc.df[,1]
head(diagnosis)
```

> Q1. How many observations are in the wisc.data and diagnosis datasets?

```{r}
nrow(wisc.data)
length(diagnosis)
```

> Q2. How many of the observations have a malignant diagnosis?

```{r}
diagnosis <- as.factor(wisc.df$diagnosis)
table(diagnosis)
```

> Q3. How many variables/features in the data are suffixed with _mean?

```{r}
length(grep("_mean", colnames(wisc.df)))
```

Performing PCA

Check the means and standard deviations of the columns 

```{r}
colMeans(wisc.data)

apply(wisc.data,2,sd)
```

```{r}
ncol(wisc.data)
```
```{r}
wisc.data <- wisc.data[,-31]
head(wisc.data)
```

```{r}
# Perform PCA on wisc.data by completing the following code
wisc.pr <- prcomp(wisc.data, scale=TRUE)
summary(wisc.pr)
```

> Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?
> 0.4427 or 44.27%

> Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?
> 3

> Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?
> 7

```{r}
biplot(wisc.pr)
```

> Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?
> The quality of this plot is very poor and uninformative. The plot uses row names as the datapoints making it impossible to idenitfy any trends or clusters in the data.  

```{r}
# Scatter plot observations by components 1 and 2
plot(wisc.pr$x[,1:2], col = diagnosis)
```

```{r}
# Repeat for components 1 and 3
plot(wisc.pr$x[,c(1,3)], col = diagnosis, 
     xlab = "PC1", ylab = "PC3")
```

> Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?
> There is better separation of the data in the first plot. This is because PC 2 explains for of the variance in the data than PC 3.

Make a plot using ggplot
```{r}
# Create a data.frame for ggplot
df <- as.data.frame(wisc.pr$x)
df$diagnosis <- diagnosis

# Load the ggplot2 package
library(ggplot2)

# Make a scatter plot colored by diagnosis
ggplot(df) + 
  aes(PC1, PC2, col=diagnosis) + 
  geom_point()
```

```{r}
# Calculate variance of each component
pr.var <- wisc.pr$sdev^2
head(pr.var)
```

```{r}
# Variance explained by each principal component: pve
pve <- pr.var / sum(pr.var)
print(pve)

# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```

```{r}
# Alternative scree plot of the same data, note data driven y-axis
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```

```{r}
## ggplot based graph
library(factoextra)
fviz_eig(wisc.pr, addlabels = TRUE)
```

> Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?
>Answer:-0.26085376

```{r}
wisc.pr$rotation[,1]
```

> Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?
> 5 PCs

```{r}
summary(wisc.pr)
```

# Hierarchical Clustering 

```{r}
# Scale the wisc.data data using the "scale()" function
data.scaled <- scale(wisc.data)
```

```{r}
# Calculate the (Euclidean) distances between all pairs of observations in the new scaled dataset 
data.dist <- dist(data.scaled)
```

```{r}
# Create a hierarchical clustering model using complete linkage.
wisc.hclust <- hclust(data.dist, method = "complete")
```

# Results of Hierarchical Clustering

```{r}
plot(wisc.hclust)
abline(h=19, col="red", lty=2)
```
> Q11. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?
> height = 19

# Selecting number of clusters

```{r}
# Use cutree() to cut the tree so that it has 4 clusters
wisc.hclust.clusters <- cutree(wisc.hclust, k=4)
```

```{r}
# We can use the table() function to compare the cluster membership to the actual diagnoses.
table(wisc.hclust.clusters, diagnosis)
```
> Q12. Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10?
> A smaller number of clusters (i.e. 1-3) do not separate out the data well; both the benign and malignant datapoints fall within the same cluster. Increasing the number of clusters helps to separate the data more, but cutting into too many clusters (i.e. >7) doesn't provide additional useful information. 

```{r}
for (i in 2:10) {
  table <- table(cutree(wisc.hclust, k=i), diagnosis)
  print(table)
}
```

> Q13. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.
> My favorite result uses the ward.D2 method. I believe that this plot provides the most information, is the easiest to understand, and is the most visually pleasing. This is in comparison to the "single" method which doesn't provided any clustering, the "average" method in which the clusters are hard to identify, and the "complete" method where the data are messier/squished together.

```{r}
for (i in c("single", "complete", "average", "ward.D2")) {
  wisc.hclust <- hclust(data.dist, method = i)
  plot(wisc.hclust)
}
```

# K-means clustering and comparing results

Create a k-means model on wisc.data and assign the result to wisc.km. Create 2 clusters corresponding to the actual number of diagnosis. Scale the data using the scale() function and repeat the algorithm 20 times 

```{r}
wisc.km <- kmeans(scale(wisc.data), centers= 2, nstart= 20)
```

Use the table() function to compare the cluster membership of the k-means model (wisc.km$cluster) to the actual diagnoses contained in the diagnosis vector.

```{r}
table(wisc.km$cluster, diagnosis)
```
> Q14. How well does k-means separate the two diagnoses? How does it compare to your hclust results?
> k-means separates the diagnoses into 2 distinct clusters whereas wisc.hclust.clusters separated the diagnoses into 4 clusters where clusters 1 and 3 contain the majority of the datapoints. Clusters 1 and 3 in the wisc.hclust.clusters dataset and clusters 1 and 2 in the wisc.km dataset are very similar. Both separate the diagnoses well. 

Use the table() function to compare the cluster membership of the k-means model (wisc.km$cluster) to your hierarchical clustering model from above (wisc.hclust.clusters).

```{r}
table(wisc.hclust.clusters, wisc.km$cluster)
```

# Combining Methods

Using the minimum number of PCs required to describe at least 90% of the variability in the data, create a hierarchical clustering model with the linkage method="ward.D2"

```{r}
wisc.pr.hclust <- hclust(dist(wisc.pr$x[, 1:7]), method = "ward.D2")
  plot(wisc.pr.hclust)
```

```{r}
grps <- cutree(wisc.pr.hclust, k=2)
table(grps)
```

```{r}
table(grps, diagnosis)
```

```{r}
plot(wisc.pr$x[,1:2], col=grps)
```

```{r}
plot(wisc.pr$x[,1:2], col=diagnosis)
```

Turn groups into a factor and reorder the levels

```{r}
g <- as.factor(grps)
levels(g)
```

```{r}
g <- relevel(g,2)
levels(g)
```

Plot data using the re-ordered factor 

```{r}
plot(wisc.pr$x[,1:2], col=g)
```

Use the distance along the first 7 PCs for clustering i.e. wisc.pr$x[, 1:7]

```{r}
wisc.pr.hclust <- hclust(dist(wisc.pr$x[, 1:7]), method="ward.D2")
```

Cut this hierarchical clustering model into 4 clusters and assign the results to wisc.pr.hclust.clusters

```{r}
wisc.pr.hclust.clusters_2 <- cutree(wisc.pr.hclust, k=2) 
# clustering on PCA results with 2 clusters

wisc.pr.hclust.clusters_4 <- cutree(wisc.pr.hclust, k=4) # clustering on PCA results with 4 clusters
```

>Q15. How well does the newly created model with four clusters separate out the two diagnoses?
>The newly created model generates 4 clusters where clusters 1, 2, and 3 are derived from cluster 1 when the model was cut into 2 clusters. Cluster 4 is equivalent to the cluster 2 in the 2 cluster model. 

Using table(), compare the results from your new hierarchical clustering model with the actual diagnoses.

```{r}
table(wisc.pr.hclust.clusters_2, diagnosis)
table(wisc.pr.hclust.clusters_4, diagnosis)
```

```{r}
table(wisc.km$cluster, diagnosis)
table(wisc.hclust.clusters, diagnosis)
```

>Q16. How well do the k-means and hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses?
>Both clustering models do a good job separating the diagnoses. wisc.hclust.clusters generates 4 clusters, whereas clusters 1, 2, and 4 are nearly equivalent to cluster 1 generated by k-means. However, clusters 2 and 4 generated by hierarchical clustering contain very few datapoints.

# Sensitivity/Specificity

>Q17. Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?
>The analyses that resulted in the best specificity were hierarchical clustering and k-means clustering. Both of these analyses were correctly able to idenitfy 96% of ill patients. The analysis with the best sensitivity was hierarchical clustering combined with PCA. This analysis corrected rejected 87% of healthy patients. 

# Prediction

Use the predict() function to take our PCA model from before and new cancer cell data and project that data onto our PCA space.

```{r}
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

```{r}
plot(wisc.pr$x[,1:2], col=g)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```

>Q18. Which of these new patients should we prioritize for follow up based on your results?
>Patient 2 should be priortized for a follow-up since they cluster with the malignant cluster

Here we use the sessionInfo() function to report on our R systems setup at the time of document execution.

```{r}
sessionInfo()
```


